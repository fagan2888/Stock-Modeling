{
 "cells": [
  {
   "cell_type": "heading",
   "metadata": {
    "collapsed": true
   },
   "level": 2,
   "source": [
    "Final Project: Stock Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook models stock data that has been pre-processed with news sentiment data, then predicts the Closing, High, and Low values for the current buisness day and following business day. Below is the process for preparing the data then modeling the data for the best predictions."
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Section 1: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "\n",
    "# Set Console formatting for panda prints\n",
    "pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# **********************************************************************************************************************\n",
    "# Modeling / Prepare Data\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/mwilchek/Stock-Modeling/master/DJ_NEWS_SENTIMENT_DATA.csv')\n",
    "data['Cycle_Change'] = data.Max_Sentiment.eq(data.Max_Sentiment.shift())\n",
    "dummies = pd.get_dummies(data.Cycle_Change)\n",
    "data.join(dummies)\n",
    "data_tomorrow = data\n",
    "\n",
    "# Move certain columns up by one row for data_tomorrow\n",
    "data_tomorrow.Anger = data_tomorrow.Anger.shift(+1)\n",
    "data_tomorrow.Anticipation = data_tomorrow.Anticipation.shift(+1)\n",
    "data_tomorrow.Disgust = data_tomorrow.Disgust.shift(+1)\n",
    "data_tomorrow.Fear = data_tomorrow.Fear.shift(+1)\n",
    "data_tomorrow.Joy = data_tomorrow.Joy.shift(+1)\n",
    "data_tomorrow.Sadness = data_tomorrow.Sadness.shift(+1)\n",
    "data_tomorrow.Surprise = data_tomorrow.Surprise.shift(+1)\n",
    "data_tomorrow.Trust = data_tomorrow.Trust.shift(+1)\n",
    "data_tomorrow.Negative = data_tomorrow.Negative.shift(+1)\n",
    "data_tomorrow.Positive = data_tomorrow.Positive.shift(+1)\n",
    "data_tomorrow.Max_Sentiment = data_tomorrow.Max_Sentiment.shift(+1)\n",
    "data_tomorrow.Sentiment_Proportion = data_tomorrow.Sentiment_Proportion.shift(+1)\n",
    "\n",
    "# Delete the first row of data_tomorrow\n",
    "data_tomorrow.drop(data_tomorrow.head(1).index, inplace=True)\n",
    "\n",
    "train_data = data[:-1]  # train data\n",
    "today_record = data.tail(1)  # test data (validate current day and predict from following day)\n",
    "train_data_tomorrow = data_tomorrow[:-1]  # train data\n",
    "tomorrow_record = data_tomorrow.tail(1)  # test data (validate current day and predict from following day)\n",
    "\n",
    "data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Local Functions for Accuracy Printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Local method to get Margin of Error\n",
    "def get_change(current, previous):\n",
    "    if current == previous:\n",
    "        return 100.0\n",
    "    try:\n",
    "        return (abs(current - previous) / previous) * 100.0\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Section 2: Data Modeling Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we created a pipeline of Regressor type models with a number of parameters that we tune to hopefully find an accurate model for predicting the closing value. We hope that with good results, we can mimic the process for predicting the High and Low values for the current and next business day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# MODELING EXPLORATION #################################################################################################\n",
    "# Testing best model for f(x) = Close ~ Features\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Get Feature values\n",
    "x = data[['Open', 'High', 'Low', 'False', 'True']].values\n",
    "\n",
    "# Get Target values\n",
    "y = data['Close'].values\n",
    "\n",
    "regression_models = {'lr': LinearRegression(n_jobs=-1),\n",
    "                     'mlp': MLPRegressor(random_state=0),\n",
    "                     'dt': DecisionTreeRegressor(random_state=0),\n",
    "                     'rf': RandomForestRegressor(random_state=0, n_jobs=-1),\n",
    "                     'svr': SVR(max_iter=-1)}\n",
    "\n",
    "pipe_regrs = {}\n",
    "\n",
    "# Create list of pipeline models to test with that standardize the data\n",
    "for name, regression_models in regression_models.items():\n",
    "    pipe_regrs[name] = Pipeline([('StandardScaler', StandardScaler()), ('regr', regression_models)])\n",
    "\n",
    "param_grids = {}\n",
    "\n",
    "# Linear Regression Parameter Options:\n",
    "param_grid = [{'regr__normalize': ['True']},\n",
    "              {'regr__normalize': ['False']}]\n",
    "\n",
    "# Add Linear Regression Parameters to dictionary grid\n",
    "param_grids['lr'] = param_grid\n",
    "\n",
    "# MLP Parameter Options:\n",
    "alpha_range = [10 ** i for i in range(-4, 5)]\n",
    "\n",
    "param_grid = [{'regr__hidden_layer_sizes': [10, 100, 200]}]\n",
    "\n",
    "# Add Multi-layer Perceptron Parameters to dictionary grid\n",
    "param_grids['mlp'] = param_grid\n",
    "\n",
    "# Decision Tree Regression Parameter Options:\n",
    "param_grid = [{'regr__criterion': ['mse', 'mae'],\n",
    "               'regr__min_samples_split': [2, 6, 10],\n",
    "               'regr__min_samples_leaf': [1, 6, 10],\n",
    "               'regr__max_features': ['auto', 'sqrt', 'log2']}]\n",
    "\n",
    "# Add Decision Tree Parameters to dictionary grid\n",
    "param_grids['dt'] = param_grid\n",
    "\n",
    "# Random Forest Regression Parameter Options:\n",
    "param_grid = [{'regr__n_estimators': [10, 100],\n",
    "               'regr__criterion': ['mse', 'mae'],\n",
    "               'regr__min_samples_split': [2, 6, 10],\n",
    "               'regr__min_samples_leaf': [1, 6, 10],\n",
    "               'regr__max_features': ['auto', 'sqrt', 'log2']}]\n",
    "\n",
    "# Add Random Forest Parameters to dictionary grid\n",
    "param_grids['rf'] = param_grid\n",
    "\n",
    "# Support Vector Machine (SVM) Parameter Options:\n",
    "param_grid = [{'regr__C': [0.1, 1, 10],\n",
    "               'regr__gamma': [0.1, 1, 10],\n",
    "               'regr__kernel': ['linear', 'poly', 'rbf', 'sigmoid']}]\n",
    "\n",
    "# Add SVM Parameters to dictionary grid\n",
    "param_grids['svr'] = param_grid\n",
    "\n",
    "# The list of [best_score_, best_params_, best_estimator_]\n",
    "best_score_param_estimators = []\n",
    "\n",
    "# Scoring Param: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "# For each regression\n",
    "for name in pipe_regrs.keys():\n",
    "    # GridSearchCV\n",
    "    gs = GridSearchCV(estimator=pipe_regrs[name],\n",
    "                      param_grid=param_grids[name],\n",
    "                      scoring='neg_mean_squared_error',\n",
    "                      n_jobs=1,\n",
    "                      cv=None)\n",
    "    print(\"Modeling: \" + str(pipe_regrs[name]))\n",
    "    # Fit the pipeline\n",
    "    gs = gs.fit(x, y)\n",
    "\n",
    "    # Update best_score_param_estimators\n",
    "    best_score_param_estimators.append([gs.best_score_, gs.best_params_, gs.best_estimator_])\n",
    "    print(\"Modeling Completed - Appending scores...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the user's computer, the amount of time to complete the Pipeline can be between 5-10mins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort best_score_param_estimators in descending order of the best_score_\n",
    "best_score_param_estimators = sorted(best_score_param_estimators, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# For each [best_score_, best_params_, best_estimator_]\n",
    "for best_score_param_estimator in best_score_param_estimators:\n",
    "    # Print out [best_score_, best_params_, best_estimator_], where best_estimator_ is a pipeline\n",
    "    # Since we only print out the type of classifier of the pipeline\n",
    "    print([best_score_param_estimator[0], best_score_param_estimator[1],\n",
    "           type(best_score_param_estimator[2].named_steps['regr'])], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the '{'regr__normalize': 'True'}, <class 'sklearn.linear_model.base.LinearRegression'>]' model from the Pipeline was the best scored. Let us practice predicting the cclosing value of the stock with a Linear Regression model with the best tuned parameters from our GridSearchCV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare best model from GridSearchCV where normalize set to True is the default parameter\n",
    "lr = LinearRegression(n_jobs=-1)\n",
    "\n",
    "# Fit the model with our data\n",
    "lr = lr.fit(x, y)\n",
    "\n",
    "# Predict on Today Close\n",
    "today_close = today_record[['Open', 'High', 'Low', 'False', 'True']].values\n",
    "y_pred = lr.predict(today_close)\n",
    "\n",
    "# Print Results\n",
    "print(\"Actual Closing Value: \" + str(today_record['Close'].values[0]))\n",
    "print(\"Predicted Closing Value: \" + str(y_pred[0]))\n",
    "\n",
    "error = get_change(y_pred[0], today_record['Close'].values[0])\n",
    "print(\"Accuracy error for prediction: \" + str(round(error, 4)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction results were pretty close to the actual. However, based on academic research we also want to explore OLS regression to see if there is any noticeable change in predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **********************************************************************************************#\n",
    "# OLS Regression Test\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Define formula string for Stats-model API\n",
    "formula = 'Close ~ Open + High + Low + False + True'\n",
    "\n",
    "# Define Training Data\n",
    "dta = train_data[['Close', 'Open', 'High', 'Low', 'Anger', 'Anticipation',\n",
    "                  'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise',\n",
    "                  'Trust', 'Negative', 'Positive', 'Cycle_Change', 'Sentiment_Proportion']].copy()\n",
    "\n",
    "# Set the Model\n",
    "ols_today_close_model = smf.ols(formula=formula, data=dta).fit()\n",
    "\n",
    "# Print results\n",
    "print(ols_today_close_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the model is clearly overfit based on the Adj. R Squared equaling to 1. In order to prevent overfitting, we will revise our model with a regularized fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Model with Regularized Fit to prevent over-fitting; alpha and weight values were set.\n",
    "olsUpdate_today_close = smf.ols(formula=formula, data=dta).fit_regularized(alpha=10, L1_wt=.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we practice predicting on today's record with the revised model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "print(today_record)\n",
    "\n",
    "olsUpdate_today_close_prediction = olsUpdate_today_close.predict(today_record)\n",
    "\n",
    "# Show Updated Model\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "fig = sm.graphics.plot_partregress_grid(olsUpdate_today_close_prediction, fig=fig)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would appear an OLS Regularized fit regression model is quite accurate as well to the actual value based on the above plots. If we can hyperpameter tune the sentiment values in our formula, and the alpha and weight values for the regularized parameters we may be able to create a strong model for predicting stock values with news sentiment data as a significant relationship."
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Section 3: Hyperparameter Tuning for OLS Regularized Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will create custom local methods that will find the most significant sentiment for today's stock values in Close, High, and Low using a RandForestRegressor model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
