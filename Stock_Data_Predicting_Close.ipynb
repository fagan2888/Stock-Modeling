{
 "cells": [
  {
   "cell_type": "heading",
   "metadata": {
    "collapsed": true
   },
   "level": 1,
   "source": [
    "## Read in Data and Preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before removing rows with missing values: 2007\nNumber of rows after removing rows with missing values: 2007\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/mwilchek/Stock-Modeling/master/DJ_NEWS_SENTIMENT_DATA%20eg.csv', header=0)\n",
    "\n",
    "print('Number of rows before removing rows with missing values: ' + str(data.shape[0]))\n",
    "\n",
    "# Replace ? with np.NaN\n",
    "data = data.replace('?', np.NaN)\n",
    "\n",
    "# Remove rows with np.NaN\n",
    "data = data.dropna(how='any')\n",
    "\n",
    "print('Number of rows after removing rows with missing values: ' + str(data.shape[0]))\n",
    "\n",
    "# Get Feature values\n",
    "x = data[['Open', 'High', 'Low', 'Cycle_Change']].values\n",
    "\n",
    "# Get Target values\n",
    "y = data['Close'].values\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "## Setup Models and Configure Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "regression_models = {'lr': LinearRegression(n_jobs=-1),\n",
    "                     'mlp': MLPRegressor(random_state=0),\n",
    "                     'dt': DecisionTreeRegressor(random_state=0),\n",
    "                     'rf': RandomForestRegressor(random_state=0, n_jobs=-1),\n",
    "                     'svr': SVR(max_iter=-1)}\n",
    "\n",
    "pipe_regrs = {}\n",
    "\n",
    "# Create list of pipeline models to test with that standardize the data\n",
    "for name, regression_models in regression_models.items():\n",
    "    pipe_regrs[name] = Pipeline([('StandardScaler', StandardScaler()), ('regr', regression_models)])\n",
    "\n",
    "param_grids = {}\n",
    "\n",
    "# Linear Regression Parameter Options:\n",
    "param_grid = [{'regr__normalize': ['True']},\n",
    "              {'regr__normalize': ['False']}]\n",
    "\n",
    "# Add Linear Regression Parameters to dictionary grid\n",
    "param_grids['lr'] = param_grid\n",
    "\n",
    "# MLP Parameter Options:\n",
    "alpha_range = [10 ** i for i in range(-4, 5)]\n",
    "\n",
    "param_grid = [{'regr__hidden_layer_sizes': [10, 100, 200],\n",
    "               'regr__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "               'regr__solver': ['lbfgs', 'sgd', 'adam'],\n",
    "               'regr__alpha': alpha_range},\n",
    "              {'regr__hidden_layer_sizes': [30, 30, 30],\n",
    "               'regr__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "               'regr__solver': ['lbfgs', 'sgd', 'adam'],\n",
    "               'regr__alpha': alpha_range}]\n",
    "\n",
    "# Add Multi-layer Perceptron Parameters to dictionary grid\n",
    "param_grids['mlp'] = param_grid\n",
    "\n",
    "# Decision Tree Regression Parameter Options:\n",
    "param_grid = [{'regr__criterion': ['mse', 'friedman_mse', 'mae'],\n",
    "               'regr__min_samples_split': [2, 6, 10, 20, 30, 40, 50],\n",
    "               'regr__min_samples_leaf': [1, 6, 10, 20, 30, 40, 50],\n",
    "               'regr__max_features': ['auto', 'int', 'float', 'sqrt', 'log2']}]\n",
    "\n",
    "# Add Decision Tree Parameters to dictionary grid\n",
    "param_grids['dt'] = param_grid\n",
    "\n",
    "# Random Forest Regression Parameter Options:\n",
    "param_grid = [{'regr__n_estimators': [10, 100, 1000],\n",
    "               'regr__criterion': ['mse', 'mae'],\n",
    "               'regr__min_samples_split': [2, 6, 10, 20, 30, 40, 50],\n",
    "               'regr__min_samples_leaf': [1, 6, 10, 20, 30, 40, 50],\n",
    "               'regr__max_features': ['auto', 'int', 'float', 'sqrt', 'log2']}]\n",
    "\n",
    "# Add Random Forest Parameters to dictionary grid\n",
    "param_grids['rf'] = param_grid\n",
    "\n",
    "# Support Vector Machine (SVM) Parameter Options:\n",
    "param_grid = [{'regr__C': [0.01, 0.1, 1, 10, 100],\n",
    "               'regr__gamma': [0.01, 0.1, 1, 10, 100],\n",
    "               'regr__kernel': ['linear', 'poly', 'rbf', 'sigmoid']}]\n",
    "\n",
    "# Add SVM Parameters to dictionary grid\n",
    "param_grids['svr'] = param_grid\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "## Loop through Pipeline models with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# The list of [best_score_, best_params_, best_estimator_]\n",
    "best_score_param_estimators = []\n",
    "\n",
    "# Scoring Param: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "# For each regression\n",
    "for name in pipe_regrs.keys():\n",
    "    # GridSearchCV\n",
    "    gs = GridSearchCV(estimator=pipe_regrs[name],\n",
    "                      param_grid=param_grids[name],\n",
    "                      scoring='neg_mean_squared_error',\n",
    "                      n_jobs=1,\n",
    "                      cv=None)\n",
    "\n",
    "    # Fit the pipeline\n",
    "    gs = gs.fit(x, y)\n",
    "\n",
    "    # Update best_score_param_estimators\n",
    "    best_score_param_estimators.append([gs.best_score_, gs.best_params_, gs.best_estimator_])"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "## Sort Scores and Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_score_param_estimators' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7d52c76dc805>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Sort best_score_param_estimators in descending order of the best_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbest_score_param_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_score_param_estimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# For each [best_score_, best_params_, best_estimator_]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbest_score_param_estimator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbest_score_param_estimators\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_score_param_estimators' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Sort best_score_param_estimators in descending order of the best_score_\n",
    "best_score_param_estimators = sorted(best_score_param_estimators, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# For each [best_score_, best_params_, best_estimator_]\n",
    "for best_score_param_estimator in best_score_param_estimators:\n",
    "    # Print out [best_score_, best_params_, best_estimator_], where best_estimator_ is a pipeline\n",
    "    # Since we only print out the type of classifier of the pipeline\n",
    "    print([best_score_param_estimator[0], best_score_param_estimator[1], type(best_score_param_estimator[2].named_steps['regr'])], end='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
